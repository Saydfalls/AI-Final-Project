{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#The Following is a demonstration of Neural Networks working on the same dataset in order to compete and compare the strengths and weaknesses of each."
      ],
      "metadata": {
        "id": "z8P1ossbM_gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is all the imports that will be used for the rest of the code cells"
      ],
      "metadata": {
        "id": "G5F8847XK1u0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Nzkg9gA66NH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "from keras.regularizers import L2\n",
        "from keras.constraints import max_norm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras. models import Sequential\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional Neural Network"
      ],
      "metadata": {
        "id": "qbKVf4W0m5ZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the model architecture with 10 layers reaching a result I wasn't able to further optimize with the 10 layer restriction."
      ],
      "metadata": {
        "id": "arrX61-nK8yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Data\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Data Preprocessing\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "\n",
        "# CNN model architecture\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((3, 3)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "# CIFAR-10 dataset has 10 classes so the last layer specifies that\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "# Hyperparameters set before training model\n",
        "# learning rate and batch size\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# demonstrating a summary of the model architecture\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN74-6KXQNfu",
        "outputId": "e30e6321-8c27-4013-d0b3-11a329b57bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_27 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 10, 10, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 8, 8, 64)          18496     \n",
            "                                                                 \n",
            " batch_normalization_43 (Ba  (None, 8, 8, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 6, 6, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 3, 3, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 1, 1, 128)         73856     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 148234 (579.04 KB)\n",
            "Trainable params: 148106 (578.54 KB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the model being trained and the epoch restriction of 10 being applied as well. This will result in a graph that demonstrates accuracy as well as validation accuracy."
      ],
      "metadata": {
        "id": "7oQONpjvMCYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "predictions = model.predict(test_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbN4MIfhybTa",
        "outputId": "3fe53cb9-90b0-4d89-a91c-93a8975f3a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.3476 - accuracy: 0.5145 - val_loss: 1.1624 - val_accuracy: 0.5906\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9682 - accuracy: 0.6589 - val_loss: 1.6506 - val_accuracy: 0.4933\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8378 - accuracy: 0.7044 - val_loss: 1.3220 - val_accuracy: 0.5475\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7487 - accuracy: 0.7373 - val_loss: 1.0006 - val_accuracy: 0.6623\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6848 - accuracy: 0.7589 - val_loss: 0.9735 - val_accuracy: 0.6855\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6285 - accuracy: 0.7776 - val_loss: 0.9131 - val_accuracy: 0.6916\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5840 - accuracy: 0.7944 - val_loss: 0.9958 - val_accuracy: 0.6844\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5438 - accuracy: 0.8068 - val_loss: 1.1953 - val_accuracy: 0.6488\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4993 - accuracy: 0.8210 - val_loss: 1.0254 - val_accuracy: 0.6865\n",
            "Epoch 10/10\n",
            " 377/1563 [======>.......................] - ETA: 5s - loss: 0.4296 - accuracy: 0.8501"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the results being adapted for a confusion matrix for better visualization."
      ],
      "metadata": {
        "id": "88c-oDLrMlds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model predictions prepped for confusion matrix\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Create the confusion matrix\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
        "\n",
        "# Display the confusion matrix\n",
        "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
        "disp.plot(cmap='bone_r', values_format=\".4g\", xticks_rotation='vertical')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "URoWoZLEMBW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Residual Neural Network"
      ],
      "metadata": {
        "id": "UvYNnr-qMlWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the model architecture for a Residual Neural Network. As you can tell we remain within the bounds of the 10 model layer limit and we continue on with the same process. Notice the differences between the CNN and this ResNet."
      ],
      "metadata": {
        "id": "CdsGQdEeM48h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = 10\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Load pre-trained ResNet50 model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Normalize input data for ResNet50\n",
        "train_images, test_images = preprocess_input(train_images), preprocess_input(test_images)\n",
        "\n",
        "# Create a custom top for classification\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.Dense(32, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))  # Output layer for classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary to check the architecture\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "l6I1uF2HRSu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the ResNet being trained and demonstating accuracy and validation results."
      ],
      "metadata": {
        "id": "k1ec4i1wNqgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input).flow(test_images, test_labels, batch_size=32, shuffle=False)\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gmUYO2jAwzSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the preparation of the confusion matrix for the ResNet as well as the demonstration of the matrix."
      ],
      "metadata": {
        "id": "O0Yr5bo2N5tW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
        "disp.plot(cmap='bone_r', values_format=\".4g\", xticks_rotation='vertical')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2VIzROZoli97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Capsule Neural Network"
      ],
      "metadata": {
        "id": "fDYoHJqQnaZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we reload the dataset as a precaution due to prior complications with the Capsule Network model architecture."
      ],
      "metadata": {
        "id": "H1kD2hseODMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Convert labels to integers\n",
        "train_labels = train_labels.astype(int)\n",
        "test_labels = test_labels.astype(int)"
      ],
      "metadata": {
        "id": "dBvhF8jenXku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the model architecture for the CapsNet. The model layers are created within the build_capsule_network function. Notice how they differ from both the CNN and ResNet."
      ],
      "metadata": {
        "id": "-nJ2VZAnOUVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining capsule layer class for CapsNet\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    def __init__(self, num_capsules, capsule_dim, routings=3):\n",
        "        super(CapsuleLayer, self).__init__()\n",
        "        self.num_capsules = num_capsules\n",
        "        self.capsule_dim = capsule_dim\n",
        "        self.routings = routings\n",
        "        self.activation = squash\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        self.kernel = self.add_weight(\n",
        "            name='capsule_kernel',\n",
        "            shape=(self.num_capsules, input_shape[-1], self.capsule_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True,\n",
        "        )\n",
        "        super(CapsuleLayer, self).build(input_shape)\n",
        "\n",
        "def call(self, inputs):\n",
        "    # Expand the dimensions of the input tensor\n",
        "    inputs_expanded = tf.expand_dims(inputs, axis=-2)\n",
        "\n",
        "    # Tile the input tensor along the capsule dimensions\n",
        "    inputs_tiled = tf.tile(inputs_expanded, [1, 1, 1, self.num_capsules, 1])\n",
        "\n",
        "    # Tile the capsule kernel along the input dimensions\n",
        "    kernel_tiled = tf.tile(self.kernel, [1, 1, 1, tf.shape(inputs)[-2]])\n",
        "\n",
        "    # Compute the dot product between the input tensor and the capsule kernel\n",
        "    votes = tf.reduce_sum(inputs_tiled * kernel_tiled, axis=-1)\n",
        "\n",
        "    # Routing by agreement\n",
        "    # Determines the weight between different capsules\n",
        "    # between one layer and its subsequent layers.\n",
        "    logit_shape = votes.shape[:-1]\n",
        "    b = tf.zeros(logit_shape)\n",
        "    for i in range(self.routings):\n",
        "        c = tf.nn.softmax(b, axis=1)\n",
        "        outputs = self.activation(tf.reduce_sum(c[..., None] * votes, axis=-2))\n",
        "        if i < self.routings - 1:\n",
        "            b += tf.reduce_sum(outputs[..., None] * votes, axis=-1)\n",
        "    return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsules, self.capsule_dim)\n",
        "\n",
        "def squash(vector):\n",
        "    squared_norm = tf.reduce_sum(tf.square(vector), axis=-1, keepdims=True)\n",
        "    scale = squared_norm / (1 + squared_norm)\n",
        "    return scale * vector / tf.sqrt(squared_norm + tf.keras.backend.epsilon())\n",
        "\n",
        "# Define CapsuleLayer and squash function as you have done\n",
        "\n",
        "def build_capsule_network(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Convolutional layers with Batch Normalization\n",
        "    conv1 = layers.Conv2D(128, (3, 3), activation='relu')(inputs)\n",
        "    conv1 = layers.BatchNormalization()(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(64, (3, 3), activation='relu')(conv1)\n",
        "    conv2 = layers.BatchNormalization()(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(32, (3, 3), activation='relu')(conv2)\n",
        "    conv3 = layers.BatchNormalization()(conv3)\n",
        "\n",
        "    # Primary Capsule layer\n",
        "    primary_capsules = CapsuleLayer(num_capsules=8, capsule_dim=16)(conv3)\n",
        "\n",
        "    # Flatten Capsules for Output\n",
        "    flattened_capsules = layers.Reshape((-1,))(primary_capsules)\n",
        "\n",
        "    # Dense layers with Batch Normalization\n",
        "    dense1 = layers.Dense(128, activation='relu')(flattened_capsules)\n",
        "    dense1 = layers.BatchNormalization()(dense1)\n",
        "\n",
        "    dense2 = layers.Dense(64, activation='relu')(dense1)\n",
        "    dense2 = layers.BatchNormalization()(dense2)\n",
        "\n",
        "    # Output Layer\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(dense2)\n",
        "\n",
        "    # Building the model\n",
        "    model = models.Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 5:\n",
        "        lr *= 1e-1\n",
        "    elif epoch > 10:\n",
        "        lr *= 1e-2\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Convert labels to integers\n",
        "train_labels = train_labels.astype(int)\n",
        "test_labels = test_labels.astype(int)\n",
        "\n",
        "# Build and compile the model\n",
        "num_classes = 10\n",
        "model = build_capsule_network(input_shape=(32, 32, 3), num_classes=num_classes)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "SZELvNNEnu4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and demonstrating the models accuracy."
      ],
      "metadata": {
        "id": "JFC5hsSDPdqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input).flow(test_images, test_labels, batch_size=32, shuffle=False)\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U_X8VFVenxCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix is prepared and presented for the CapsNet model."
      ],
      "metadata": {
        "id": "j-t6CXuePiql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
        "\n",
        "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
        "disp.plot(cmap='bone_r', values_format=\".4g\", xticks_rotation='vertical')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mCHUeL5yn8Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An additional manual accuracy statement was added in due to complications with adding it into the previous code cells. I wanted to be persistent, however, so I demonstrated it by its lonesome."
      ],
      "metadata": {
        "id": "b8rZMFMxQHXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "print(f\"Manual Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "Vm5kPIVmoAwZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}